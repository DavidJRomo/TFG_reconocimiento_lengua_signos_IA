Este software parte del repositorio de código abierto https://github.com/kinivi/hand-gesture-recognition-mediapipe

Los objetivos de este proyecto son, por un lado, facilitar a personas con dificultades en el habla la comunicación con otros usuarios durante una video llamada, pudiendo realizar gestos frente a la cámara, y traduciéndose en tiempo real para el resto de los miembros de la llamada. Por otro lado, mejorar la docencia de aquellos profesores que imparten clases online, ofreciéndoles la posibilidad de realizar trazos y crear figuras en pantalla, usando únicamente sus manos frente a la cámara.

Para lograr estos objetivos se hará uso de los avances en los modelos de inteligencia artificial los cuales nos permitirán, durante una grabación de video, detectar las manos del usuario y seguirlas en tiempo real. Durante el seguimiento de las manos, analizaremos los gestos que realiza el usuario y realizaremos las acciones correspondientes.

El modelo encargado de la detección del lenguaje de signos será entrenado con todos los gestos que componen el abecedario de la lengua de signos española. De esta forma seremos capaces de generar un subtitulo según los gestos registrados y permitirá al resto de usuarios leer y entender que se está comunicando. En cuanto al modelo de pizarra digital, se entrenará con unos gestos específicos para las diferentes acciones, los cuales permitirán al usuario tanto dibujar en la  antalla, como modificar el trazo o borrarlo.

Tras terminar el desarrollo de la aplicación , se creará un ejecutable que permitirá a los usuarios que la usen, tener acceso a todas las funcionalidades planteadas como objetivos de este proyecto. 
